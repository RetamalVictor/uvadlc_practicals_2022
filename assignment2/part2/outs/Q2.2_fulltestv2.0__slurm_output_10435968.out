Running experiment on cifar10 with fixed_patch and prompt size 1
Namespace(print_freq=25, save_freq=50, batch_size=128, num_workers=3, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=7, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='This is a photo of a {}', visualize_prompt=False, root='/scratch/lcur0649', dataset='cifar10', image_size=224, test_noise=False, seed=0, model_dir='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/checkpoints', image_dir='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume=None, evaluate=False, gpu=None, use_wandb=False, device='cuda', model_folder='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/checkpoints/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /scratch/lcur0649/cifar-10-python.tar.gz
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 65536/170498071 [00:00<08:10, 347240.37it/s]  0%|          | 163840/170498071 [00:00<06:28, 438318.86it/s]  0%|          | 327680/170498071 [00:00<03:32, 801126.43it/s]  0%|          | 557056/170498071 [00:00<02:17, 1239149.22it/s]  1%|          | 1048576/170498071 [00:00<01:13, 2317611.22it/s]  1%|          | 2064384/170498071 [00:00<00:36, 4630012.74it/s]  2%|▏         | 3833856/170498071 [00:00<00:19, 8475951.55it/s]  3%|▎         | 5799936/170498071 [00:00<00:14, 11733062.05it/s]  5%|▍         | 7766016/170498071 [00:01<00:11, 14079559.41it/s]  6%|▌         | 9895936/170498071 [00:01<00:09, 16150361.71it/s]  7%|▋         | 12124160/170498071 [00:01<00:08, 17922423.24it/s]  9%|▊         | 14516224/170498071 [00:01<00:07, 19643766.11it/s] 10%|▉         | 16515072/170498071 [00:01<00:09, 16537686.77it/s] 11%|█         | 18284544/170498071 [00:01<00:11, 13135919.00it/s] 12%|█▏        | 19824640/170498071 [00:01<00:11, 13627657.57it/s] 13%|█▎        | 21528576/170498071 [00:01<00:10, 14384091.52it/s] 14%|█▎        | 23330816/170498071 [00:02<00:09, 15220886.42it/s] 15%|█▍        | 25329664/170498071 [00:02<00:08, 16443499.24it/s] 16%|█▌        | 27492352/170498071 [00:02<00:08, 17822217.45it/s] 17%|█▋        | 29687808/170498071 [00:02<00:07, 18978043.92it/s] 19%|█▊        | 31916032/170498071 [00:02<00:06, 19898916.55it/s] 20%|██        | 34111488/170498071 [00:02<00:06, 20375086.78it/s] 21%|██▏       | 36438016/170498071 [00:02<00:06, 21186796.93it/s] 23%|██▎       | 38764544/170498071 [00:02<00:06, 21744042.92it/s] 24%|██▍       | 41091072/170498071 [00:02<00:05, 22186056.05it/s] 25%|██▌       | 43450368/170498071 [00:02<00:05, 22558986.42it/s] 27%|██▋       | 45809664/170498071 [00:03<00:05, 22853007.85it/s] 28%|██▊       | 48267264/170498071 [00:03<00:05, 23303928.72it/s] 30%|██▉       | 50626560/170498071 [00:03<00:05, 23274922.91it/s] 31%|███       | 53084160/170498071 [00:03<00:04, 23485452.20it/s] 33%|███▎      | 55541760/170498071 [00:03<00:04, 23790100.24it/s] 34%|███▍      | 58032128/170498071 [00:03<00:04, 23825894.66it/s] 36%|███▌      | 60588032/170498071 [00:03<00:04, 24234778.73it/s] 37%|███▋      | 63143936/170498071 [00:03<00:04, 24512189.56it/s] 38%|███▊      | 65601536/170498071 [00:03<00:04, 23367705.54it/s] 40%|███▉      | 67960832/170498071 [00:04<00:04, 21637486.45it/s] 41%|████      | 70156288/170498071 [00:04<00:05, 18117735.54it/s] 42%|████▏     | 72089600/170498071 [00:04<00:05, 17917273.71it/s] 43%|████▎     | 73957376/170498071 [00:04<00:05, 17885543.43it/s] 44%|████▍     | 75825152/170498071 [00:04<00:05, 18005941.22it/s] 46%|████▌     | 77692928/170498071 [00:04<00:05, 17914225.87it/s] 47%|████▋     | 79527936/170498071 [00:04<00:05, 18028694.01it/s] 48%|████▊     | 81428480/170498071 [00:04<00:04, 18177720.04it/s] 49%|████▉     | 83329024/170498071 [00:04<00:04, 18333647.67it/s] 50%|████▉     | 85196800/170498071 [00:05<00:04, 18423962.85it/s] 51%|█████     | 87130112/170498071 [00:05<00:04, 18601502.73it/s] 52%|█████▏    | 89030656/170498071 [00:05<00:04, 18656858.83it/s] 53%|█████▎    | 90931200/170498071 [00:05<00:04, 18671592.54it/s] 54%|█████▍    | 92864512/170498071 [00:05<00:04, 18781282.01it/s] 56%|█████▌    | 94765056/170498071 [00:05<00:04, 18815586.31it/s] 57%|█████▋    | 96763904/170498071 [00:05<00:03, 19092921.81it/s] 58%|█████▊    | 98729984/170498071 [00:05<00:03, 19223006.20it/s] 59%|█████▉    | 100728832/170498071 [00:05<00:03, 19003121.84it/s] 60%|██████    | 102793216/170498071 [00:05<00:03, 19423488.60it/s] 61%|██████▏   | 104824832/170498071 [00:06<00:03, 19674096.13it/s] 63%|██████▎   | 106823680/170498071 [00:06<00:03, 19667956.19it/s] 64%|██████▍   | 108855296/170498071 [00:06<00:03, 19851294.60it/s] 65%|██████▌   | 110919680/170498071 [00:06<00:02, 20062615.72it/s] 66%|██████▋   | 112984064/170498071 [00:06<00:02, 20189745.98it/s] 67%|██████▋   | 115015680/170498071 [00:06<00:02, 20062250.60it/s] 69%|██████▊   | 117047296/170498071 [00:06<00:02, 19798919.37it/s] 70%|██████▉   | 119078912/170498071 [00:06<00:02, 19897639.41it/s] 71%|███████   | 121077760/170498071 [00:06<00:02, 19142159.15it/s] 72%|███████▏  | 123011072/170498071 [00:06<00:02, 19161471.68it/s] 73%|███████▎  | 125042688/170498071 [00:07<00:02, 19460250.26it/s] 75%|███████▍  | 127074304/170498071 [00:07<00:02, 19706184.18it/s] 76%|███████▌  | 129138688/170498071 [00:07<00:02, 19849989.99it/s] 77%|███████▋  | 131203072/170498071 [00:07<00:01, 20030961.95it/s] 78%|███████▊  | 133267456/170498071 [00:07<00:01, 20146598.19it/s] 79%|███████▉  | 135331840/170498071 [00:07<00:01, 20227712.85it/s] 81%|████████  | 137396224/170498071 [00:07<00:01, 20345039.47it/s] 82%|████████▏ | 139460608/170498071 [00:07<00:01, 20412404.48it/s] 83%|████████▎ | 141557760/170498071 [00:07<00:01, 20433026.88it/s] 84%|████████▍ | 143687680/170498071 [00:08<00:01, 20563157.84it/s] 86%|████████▌ | 145784832/170498071 [00:08<00:01, 20607529.93it/s] 87%|████████▋ | 147881984/170498071 [00:08<00:01, 20599517.79it/s] 88%|████████▊ | 150011904/170498071 [00:08<00:00, 20699379.72it/s] 89%|████████▉ | 152109056/170498071 [00:08<00:00, 20743342.45it/s] 90%|█████████ | 154206208/170498071 [00:08<00:00, 20792473.05it/s] 92%|█████████▏| 156303360/170498071 [00:08<00:00, 20757494.72it/s] 93%|█████████▎| 158400512/170498071 [00:08<00:00, 20780663.33it/s] 94%|█████████▍| 160497664/170498071 [00:08<00:00, 20822828.06it/s] 95%|█████████▌| 162594816/170498071 [00:08<00:00, 20843017.94it/s] 97%|█████████▋| 164724736/170498071 [00:09<00:00, 20945387.09it/s] 98%|█████████▊| 166821888/170498071 [00:09<00:00, 20904532.02it/s] 99%|█████████▉| 168951808/170498071 [00:09<00:00, 20984769.30it/s]100%|██████████| 170498071/170498071 [00:09<00:00, 18349096.72it/s]
Extracting /scratch/lcur0649/cifar-10-python.tar.gz to /scratch/lcur0649
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
  0%|                                               | 0.00/338M [00:00<?, ?iB/s]  5%|██                                     | 17.4M/338M [00:00<00:01, 182MiB/s] 11%|████▍                                  | 38.5M/338M [00:00<00:01, 205MiB/s] 17%|██████▋                                | 58.0M/338M [00:00<00:01, 202MiB/s] 24%|█████████▏                             | 79.4M/338M [00:00<00:01, 211MiB/s] 30%|████████████                            | 102M/338M [00:00<00:01, 221MiB/s] 37%|██████████████▋                         | 124M/338M [00:00<00:01, 210MiB/s] 44%|█████████████████▊                      | 150M/338M [00:00<00:00, 229MiB/s] 51%|████████████████████▍                   | 173M/338M [00:00<00:00, 232MiB/s] 58%|███████████████████████▏                | 196M/338M [00:00<00:00, 235MiB/s] 65%|██████████████████████████▏             | 221M/338M [00:01<00:00, 244MiB/s] 73%|█████████████████████████████▏          | 247M/338M [00:01<00:00, 252MiB/s] 81%|████████████████████████████████▏       | 272M/338M [00:01<00:00, 256MiB/s] 88%|███████████████████████████████████     | 296M/338M [00:01<00:00, 251MiB/s] 95%|█████████████████████████████████████▉  | 320M/338M [00:01<00:00, 246MiB/s]100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 234MiB/s]
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.patch'}"
Number of prompt parameters:  3
Training mode
Epoch: [0][  0/313]	Time  2.242 ( 2.242)	Data  0.750 ( 0.750)	Loss 2.0938e+00 (2.0938e+00)	Acc@1  85.94 ( 85.94)
Epoch: [0][ 25/313]	Time  0.410 ( 0.484)	Data  0.019 ( 0.046)	Loss 2.0898e+00 (2.0876e+00)	Acc@1  89.06 ( 88.91)
Epoch: [0][ 50/313]	Time  0.414 ( 0.449)	Data  0.017 ( 0.032)	Loss 2.0898e+00 (2.0877e+00)	Acc@1  86.72 ( 88.53)
Epoch: [0][ 75/313]	Time  0.409 ( 0.438)	Data  0.018 ( 0.027)	Loss 2.0840e+00 (2.0880e+00)	Acc@1  92.97 ( 88.41)
Epoch: [0][100/313]	Time  0.416 ( 0.432)	Data  0.017 ( 0.025)	Loss 2.0879e+00 (2.0875e+00)	Acc@1  88.28 ( 88.75)
Epoch: [0][125/313]	Time  0.427 ( 0.429)	Data  0.019 ( 0.023)	Loss 2.0840e+00 (2.0878e+00)	Acc@1  83.59 ( 88.62)
Epoch: [0][150/313]	Time  0.416 ( 0.426)	Data  0.017 ( 0.022)	Loss 2.0840e+00 (2.0880e+00)	Acc@1  85.94 ( 88.57)
Epoch: [0][175/313]	Time  0.407 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0879e+00 (2.0879e+00)	Acc@1  91.41 ( 88.61)
Epoch: [0][200/313]	Time  0.414 ( 0.423)	Data  0.017 ( 0.021)	Loss 2.0859e+00 (2.0879e+00)	Acc@1  87.50 ( 88.67)
Epoch: [0][225/313]	Time  0.428 ( 0.423)	Data  0.025 ( 0.020)	Loss 2.0918e+00 (2.0878e+00)	Acc@1  86.72 ( 88.68)
Epoch: [0][250/313]	Time  0.417 ( 0.422)	Data  0.016 ( 0.020)	Loss 2.0859e+00 (2.0876e+00)	Acc@1  91.41 ( 88.65)
Epoch: [0][275/313]	Time  0.419 ( 0.422)	Data  0.016 ( 0.020)	Loss 2.0781e+00 (2.0875e+00)	Acc@1  87.50 ( 88.65)
Epoch: [0][300/313]	Time  0.410 ( 0.421)	Data  0.016 ( 0.020)	Loss 2.0996e+00 (2.0874e+00)	Acc@1  85.94 ( 88.74)
Validate: [ 0/79]	Time  0.953 ( 0.953)	Loss 2.1016e+00 (2.1016e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.218 ( 0.253)	Loss 2.0898e+00 (2.0874e+00)	Prompt Acc@1  88.28 ( 89.09)
Validate: [50/79]	Time  0.219 ( 0.237)	Loss 2.0859e+00 (2.0874e+00)	Prompt Acc@1  85.94 ( 88.76)
Validate: [75/79]	Time  0.218 ( 0.232)	Loss 2.0879e+00 (2.0880e+00)	Prompt Acc@1  87.50 ( 88.66)
 * Prompt Acc@1 88.700
saved best file
Training mode
Epoch: [1][  0/313]	Time  1.147 ( 1.147)	Data  0.747 ( 0.747)	Loss 2.0938e+00 (2.0938e+00)	Acc@1  85.94 ( 85.94)
Epoch: [1][ 25/313]	Time  0.422 ( 0.446)	Data  0.016 ( 0.046)	Loss 2.0898e+00 (2.0874e+00)	Acc@1  89.06 ( 88.91)
Epoch: [1][ 50/313]	Time  0.417 ( 0.431)	Data  0.017 ( 0.032)	Loss 2.0898e+00 (2.0876e+00)	Acc@1  87.50 ( 88.54)
Epoch: [1][ 75/313]	Time  0.415 ( 0.427)	Data  0.016 ( 0.027)	Loss 2.0840e+00 (2.0879e+00)	Acc@1  92.97 ( 88.43)
Epoch: [1][100/313]	Time  0.417 ( 0.424)	Data  0.017 ( 0.024)	Loss 2.0879e+00 (2.0875e+00)	Acc@1  88.28 ( 88.75)
Epoch: [1][125/313]	Time  0.418 ( 0.423)	Data  0.017 ( 0.023)	Loss 2.0820e+00 (2.0877e+00)	Acc@1  83.59 ( 88.62)
Epoch: [1][150/313]	Time  0.420 ( 0.422)	Data  0.017 ( 0.022)	Loss 2.0840e+00 (2.0879e+00)	Acc@1  85.94 ( 88.56)
Epoch: [1][175/313]	Time  0.414 ( 0.422)	Data  0.017 ( 0.021)	Loss 2.0879e+00 (2.0878e+00)	Acc@1  91.41 ( 88.60)
Epoch: [1][200/313]	Time  0.417 ( 0.421)	Data  0.018 ( 0.021)	Loss 2.0859e+00 (2.0878e+00)	Acc@1  87.50 ( 88.65)
Epoch: [1][225/313]	Time  0.424 ( 0.421)	Data  0.029 ( 0.021)	Loss 2.0918e+00 (2.0877e+00)	Acc@1  86.72 ( 88.66)
Epoch: [1][250/313]	Time  0.411 ( 0.420)	Data  0.016 ( 0.020)	Loss 2.0859e+00 (2.0875e+00)	Acc@1  91.41 ( 88.65)
Epoch: [1][275/313]	Time  0.412 ( 0.420)	Data  0.017 ( 0.020)	Loss 2.0781e+00 (2.0874e+00)	Acc@1  87.50 ( 88.65)
Epoch: [1][300/313]	Time  0.412 ( 0.420)	Data  0.016 ( 0.020)	Loss 2.0996e+00 (2.0873e+00)	Acc@1  85.94 ( 88.75)
Validate: [ 0/79]	Time  0.941 ( 0.941)	Loss 2.1016e+00 (2.1016e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.219 ( 0.254)	Loss 2.0898e+00 (2.0874e+00)	Prompt Acc@1  88.28 ( 89.03)
Validate: [50/79]	Time  0.219 ( 0.238)	Loss 2.0859e+00 (2.0874e+00)	Prompt Acc@1  86.72 ( 88.74)
Validate: [75/79]	Time  0.219 ( 0.233)	Loss 2.0879e+00 (2.0879e+00)	Prompt Acc@1  88.28 ( 88.62)
 * Prompt Acc@1 88.660
There's no improvement for 1 epochs.
Training mode
Epoch: [2][  0/313]	Time  1.171 ( 1.171)	Data  0.734 ( 0.734)	Loss 2.0938e+00 (2.0938e+00)	Acc@1  85.94 ( 85.94)
Epoch: [2][ 25/313]	Time  0.412 ( 0.447)	Data  0.016 ( 0.045)	Loss 2.0898e+00 (2.0871e+00)	Acc@1  89.06 ( 89.03)
Epoch: [2][ 50/313]	Time  0.421 ( 0.433)	Data  0.016 ( 0.032)	Loss 2.0898e+00 (2.0874e+00)	Acc@1  87.50 ( 88.62)
Epoch: [2][ 75/313]	Time  0.417 ( 0.428)	Data  0.016 ( 0.027)	Loss 2.0840e+00 (2.0877e+00)	Acc@1  92.97 ( 88.48)
Epoch: [2][100/313]	Time  0.422 ( 0.426)	Data  0.016 ( 0.024)	Loss 2.0879e+00 (2.0873e+00)	Acc@1  88.28 ( 88.82)
Epoch: [2][125/313]	Time  0.420 ( 0.424)	Data  0.016 ( 0.023)	Loss 2.0820e+00 (2.0875e+00)	Acc@1  83.59 ( 88.69)
Epoch: [2][150/313]	Time  0.429 ( 0.423)	Data  0.016 ( 0.022)	Loss 2.0840e+00 (2.0877e+00)	Acc@1  85.94 ( 88.65)
Epoch: [2][175/313]	Time  0.412 ( 0.422)	Data  0.017 ( 0.021)	Loss 2.0879e+00 (2.0876e+00)	Acc@1  91.41 ( 88.69)
Epoch: [2][200/313]	Time  0.412 ( 0.422)	Data  0.016 ( 0.021)	Loss 2.0859e+00 (2.0876e+00)	Acc@1  87.50 ( 88.74)
Epoch: [2][225/313]	Time  0.414 ( 0.421)	Data  0.017 ( 0.020)	Loss 2.0918e+00 (2.0874e+00)	Acc@1  86.72 ( 88.74)
Epoch: [2][250/313]	Time  0.421 ( 0.421)	Data  0.018 ( 0.020)	Loss 2.0840e+00 (2.0873e+00)	Acc@1  92.19 ( 88.74)
Epoch: [2][275/313]	Time  0.420 ( 0.421)	Data  0.017 ( 0.020)	Loss 2.0762e+00 (2.0872e+00)	Acc@1  88.28 ( 88.74)
Epoch: [2][300/313]	Time  0.416 ( 0.421)	Data  0.017 ( 0.020)	Loss 2.0996e+00 (2.0870e+00)	Acc@1  85.94 ( 88.83)
Validate: [ 0/79]	Time  0.956 ( 0.956)	Loss 2.1016e+00 (2.1016e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.220 ( 0.255)	Loss 2.0898e+00 (2.0871e+00)	Prompt Acc@1  88.28 ( 89.06)
Validate: [50/79]	Time  0.220 ( 0.238)	Loss 2.0859e+00 (2.0871e+00)	Prompt Acc@1  86.72 ( 88.77)
Validate: [75/79]	Time  0.217 ( 0.233)	Loss 2.0879e+00 (2.0876e+00)	Prompt Acc@1  88.28 ( 88.66)
 * Prompt Acc@1 88.700
There's no improvement for 2 epochs.
Training mode
Epoch: [3][  0/313]	Time  1.177 ( 1.177)	Data  0.765 ( 0.765)	Loss 2.0918e+00 (2.0918e+00)	Acc@1  85.16 ( 85.16)
Epoch: [3][ 25/313]	Time  0.412 ( 0.447)	Data  0.017 ( 0.046)	Loss 2.0879e+00 (2.0870e+00)	Acc@1  89.06 ( 89.03)
Epoch: [3][ 50/313]	Time  0.412 ( 0.432)	Data  0.016 ( 0.032)	Loss 2.0898e+00 (2.0874e+00)	Acc@1  87.50 ( 88.60)
Epoch: [3][ 75/313]	Time  0.427 ( 0.428)	Data  0.016 ( 0.027)	Loss 2.0840e+00 (2.0877e+00)	Acc@1  92.97 ( 88.47)
Epoch: [3][100/313]	Time  0.417 ( 0.427)	Data  0.017 ( 0.025)	Loss 2.0879e+00 (2.0873e+00)	Acc@1  88.28 ( 88.83)
Epoch: [3][125/313]	Time  0.426 ( 0.426)	Data  0.017 ( 0.023)	Loss 2.0820e+00 (2.0875e+00)	Acc@1  83.59 ( 88.68)
Epoch: [3][150/313]	Time  0.421 ( 0.425)	Data  0.018 ( 0.023)	Loss 2.0840e+00 (2.0877e+00)	Acc@1  85.94 ( 88.63)
Epoch: [3][175/313]	Time  0.422 ( 0.425)	Data  0.018 ( 0.022)	Loss 2.0879e+00 (2.0876e+00)	Acc@1  92.19 ( 88.67)
Epoch: [3][200/313]	Time  0.425 ( 0.424)	Data  0.017 ( 0.021)	Loss 2.0859e+00 (2.0876e+00)	Acc@1  88.28 ( 88.73)
Epoch: [3][225/313]	Time  0.414 ( 0.424)	Data  0.016 ( 0.021)	Loss 2.0918e+00 (2.0874e+00)	Acc@1  86.72 ( 88.75)
Epoch: [3][250/313]	Time  0.422 ( 0.424)	Data  0.018 ( 0.020)	Loss 2.0840e+00 (2.0873e+00)	Acc@1  92.19 ( 88.76)
Epoch: [3][275/313]	Time  0.417 ( 0.423)	Data  0.018 ( 0.020)	Loss 2.0762e+00 (2.0872e+00)	Acc@1  88.28 ( 88.75)
Epoch: [3][300/313]	Time  0.425 ( 0.423)	Data  0.017 ( 0.020)	Loss 2.0996e+00 (2.0870e+00)	Acc@1  85.16 ( 88.84)
Validate: [ 0/79]	Time  0.975 ( 0.975)	Loss 2.1016e+00 (2.1016e+00)	Prompt Acc@1  82.03 ( 82.03)
Validate: [25/79]	Time  0.218 ( 0.253)	Loss 2.0898e+00 (2.0871e+00)	Prompt Acc@1  88.28 ( 89.06)
Validate: [50/79]	Time  0.218 ( 0.237)	Loss 2.0859e+00 (2.0871e+00)	Prompt Acc@1  86.72 ( 88.79)
Validate: [75/79]	Time  0.222 ( 0.232)	Loss 2.0879e+00 (2.0876e+00)	Prompt Acc@1  88.28 ( 88.71)
 * Prompt Acc@1 88.750
saved best file
Training mode
Epoch: [4][  0/313]	Time  1.070 ( 1.070)	Data  0.665 ( 0.665)	Loss 2.0918e+00 (2.0918e+00)	Acc@1  85.16 ( 85.16)
Epoch: [4][ 25/313]	Time  0.419 ( 0.449)	Data  0.017 ( 0.044)	Loss 2.0898e+00 (2.0870e+00)	Acc@1  89.06 ( 88.85)
Epoch: [4][ 50/313]	Time  0.413 ( 0.436)	Data  0.016 ( 0.031)	Loss 2.0879e+00 (2.0872e+00)	Acc@1  88.28 ( 88.53)
Epoch: [4][ 75/313]	Time  0.415 ( 0.431)	Data  0.016 ( 0.027)	Loss 2.0840e+00 (2.0876e+00)	Acc@1  92.19 ( 88.45)
Epoch: [4][100/313]	Time  0.414 ( 0.429)	Data  0.017 ( 0.024)	Loss 2.0879e+00 (2.0871e+00)	Acc@1  88.28 ( 88.79)
Epoch: [4][125/313]	Time  0.426 ( 0.427)	Data  0.016 ( 0.023)	Loss 2.0820e+00 (2.0873e+00)	Acc@1  83.59 ( 88.67)
Epoch: [4][150/313]	Time  0.422 ( 0.426)	Data  0.017 ( 0.022)	Loss 2.0840e+00 (2.0876e+00)	Acc@1  85.94 ( 88.62)
Epoch: [4][175/313]	Time  0.419 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0879e+00 (2.0875e+00)	Acc@1  92.19 ( 88.66)
Epoch: [4][200/313]	Time  0.422 ( 0.424)	Data  0.016 ( 0.021)	Loss 2.0840e+00 (2.0875e+00)	Acc@1  88.28 ( 88.73)
Epoch: [4][225/313]	Time  0.413 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0918e+00 (2.0873e+00)	Acc@1  86.72 ( 88.75)
Epoch: [4][250/313]	Time  0.416 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0840e+00 (2.0871e+00)	Acc@1  91.41 ( 88.74)
Epoch: [4][275/313]	Time  0.430 ( 0.423)	Data  0.020 ( 0.020)	Loss 2.0762e+00 (2.0870e+00)	Acc@1  89.84 ( 88.77)
Epoch: [4][300/313]	Time  0.422 ( 0.423)	Data  0.017 ( 0.019)	Loss 2.0996e+00 (2.0868e+00)	Acc@1  85.16 ( 88.86)
Validate: [ 0/79]	Time  0.928 ( 0.928)	Loss 2.1035e+00 (2.1035e+00)	Prompt Acc@1  82.03 ( 82.03)
Validate: [25/79]	Time  0.220 ( 0.253)	Loss 2.0879e+00 (2.0861e+00)	Prompt Acc@1  88.28 ( 89.06)
Validate: [50/79]	Time  0.221 ( 0.237)	Loss 2.0840e+00 (2.0859e+00)	Prompt Acc@1  86.72 ( 88.83)
Validate: [75/79]	Time  0.219 ( 0.232)	Loss 2.0879e+00 (2.0863e+00)	Prompt Acc@1  89.06 ( 88.84)
 * Prompt Acc@1 88.860
saved best file
Training mode
Epoch: [5][  0/313]	Time  1.130 ( 1.130)	Data  0.717 ( 0.717)	Loss 2.0898e+00 (2.0898e+00)	Acc@1  85.16 ( 85.16)
Epoch: [5][ 25/313]	Time  0.421 ( 0.449)	Data  0.016 ( 0.044)	Loss 2.0879e+00 (2.0850e+00)	Acc@1  89.84 ( 89.21)
Epoch: [5][ 50/313]	Time  0.417 ( 0.435)	Data  0.017 ( 0.031)	Loss 2.0859e+00 (2.0851e+00)	Acc@1  89.84 ( 88.92)
Epoch: [5][ 75/313]	Time  0.418 ( 0.430)	Data  0.016 ( 0.027)	Loss 2.0820e+00 (2.0850e+00)	Acc@1  92.19 ( 88.94)
Epoch: [5][100/313]	Time  0.419 ( 0.428)	Data  0.018 ( 0.024)	Loss 2.0840e+00 (2.0843e+00)	Acc@1  88.28 ( 89.10)
Epoch: [5][125/313]	Time  0.416 ( 0.427)	Data  0.018 ( 0.023)	Loss 2.0762e+00 (2.0844e+00)	Acc@1  86.72 ( 88.94)
Epoch: [5][150/313]	Time  0.428 ( 0.426)	Data  0.017 ( 0.022)	Loss 2.0781e+00 (2.0845e+00)	Acc@1  88.28 ( 88.84)
Epoch: [5][175/313]	Time  0.416 ( 0.425)	Data  0.019 ( 0.022)	Loss 2.0840e+00 (2.0843e+00)	Acc@1  89.06 ( 88.90)
Epoch: [5][200/313]	Time  0.420 ( 0.425)	Data  0.017 ( 0.021)	Loss 2.0781e+00 (2.0840e+00)	Acc@1  88.28 ( 88.97)
Epoch: [5][225/313]	Time  0.426 ( 0.424)	Data  0.023 ( 0.021)	Loss 2.0840e+00 (2.0837e+00)	Acc@1  86.72 ( 89.03)
Epoch: [5][250/313]	Time  0.414 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0762e+00 (2.0834e+00)	Acc@1  90.62 ( 89.03)
Epoch: [5][275/313]	Time  0.421 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0703e+00 (2.0831e+00)	Acc@1  89.84 ( 89.03)
Epoch: [5][300/313]	Time  0.418 ( 0.423)	Data  0.016 ( 0.020)	Loss 2.0957e+00 (2.0828e+00)	Acc@1  85.94 ( 89.07)
Validate: [ 0/79]	Time  0.984 ( 0.984)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.216 ( 0.254)	Loss 2.0820e+00 (2.0817e+00)	Prompt Acc@1  89.06 ( 88.91)
Validate: [50/79]	Time  0.220 ( 0.238)	Loss 2.0801e+00 (2.0814e+00)	Prompt Acc@1  87.50 ( 89.08)
Validate: [75/79]	Time  0.218 ( 0.232)	Loss 2.0840e+00 (2.0818e+00)	Prompt Acc@1  88.28 ( 89.03)
 * Prompt Acc@1 89.050
saved best file
Training mode
Epoch: [6][  0/313]	Time  1.237 ( 1.237)	Data  0.805 ( 0.805)	Loss 2.0859e+00 (2.0859e+00)	Acc@1  87.50 ( 87.50)
Epoch: [6][ 25/313]	Time  0.426 ( 0.454)	Data  0.017 ( 0.048)	Loss 2.0840e+00 (2.0812e+00)	Acc@1  89.06 ( 88.94)
Epoch: [6][ 50/313]	Time  0.423 ( 0.438)	Data  0.016 ( 0.033)	Loss 2.0820e+00 (2.0815e+00)	Acc@1  90.62 ( 88.88)
Epoch: [6][ 75/313]	Time  0.426 ( 0.432)	Data  0.017 ( 0.028)	Loss 2.0781e+00 (2.0818e+00)	Acc@1  93.75 ( 88.81)
Epoch: [6][100/313]	Time  0.420 ( 0.429)	Data  0.016 ( 0.025)	Loss 2.0820e+00 (2.0813e+00)	Acc@1  88.28 ( 88.98)
Epoch: [6][125/313]	Time  0.422 ( 0.428)	Data  0.017 ( 0.024)	Loss 2.0742e+00 (2.0816e+00)	Acc@1  88.28 ( 88.85)
Epoch: [6][150/313]	Time  0.428 ( 0.427)	Data  0.017 ( 0.023)	Loss 2.0762e+00 (2.0818e+00)	Acc@1  89.06 ( 88.72)
Epoch: [6][175/313]	Time  0.419 ( 0.426)	Data  0.016 ( 0.022)	Loss 2.0820e+00 (2.0817e+00)	Acc@1  90.62 ( 88.73)
Epoch: [6][200/313]	Time  0.418 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0762e+00 (2.0815e+00)	Acc@1  88.28 ( 88.81)
Epoch: [6][225/313]	Time  0.433 ( 0.425)	Data  0.017 ( 0.021)	Loss 2.0820e+00 (2.0813e+00)	Acc@1  86.72 ( 88.87)
Epoch: [6][250/313]	Time  0.428 ( 0.425)	Data  0.017 ( 0.021)	Loss 2.0762e+00 (2.0812e+00)	Acc@1  89.84 ( 88.89)
Epoch: [6][275/313]	Time  0.425 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0684e+00 (2.0810e+00)	Acc@1  88.28 ( 88.92)
Epoch: [6][300/313]	Time  0.413 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0938e+00 (2.0808e+00)	Acc@1  86.72 ( 88.98)
Validate: [ 0/79]	Time  0.914 ( 0.914)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.218 ( 0.252)	Loss 2.0801e+00 (2.0808e+00)	Prompt Acc@1  89.84 ( 88.85)
Validate: [50/79]	Time  0.221 ( 0.237)	Loss 2.0781e+00 (2.0803e+00)	Prompt Acc@1  87.50 ( 88.92)
Validate: [75/79]	Time  0.220 ( 0.232)	Loss 2.0820e+00 (2.0808e+00)	Prompt Acc@1  88.28 ( 88.96)
 * Prompt Acc@1 89.010
There's no improvement for 1 epochs.
Training mode
Epoch: [7][  0/313]	Time  1.139 ( 1.139)	Data  0.721 ( 0.721)	Loss 2.0859e+00 (2.0859e+00)	Acc@1  89.06 ( 89.06)
Epoch: [7][ 25/313]	Time  0.421 ( 0.447)	Data  0.016 ( 0.044)	Loss 2.0840e+00 (2.0802e+00)	Acc@1  89.06 ( 89.06)
Epoch: [7][ 50/313]	Time  0.415 ( 0.434)	Data  0.016 ( 0.031)	Loss 2.0801e+00 (2.0807e+00)	Acc@1  90.62 ( 89.06)
Epoch: [7][ 75/313]	Time  0.423 ( 0.430)	Data  0.018 ( 0.026)	Loss 2.0781e+00 (2.0810e+00)	Acc@1  92.19 ( 88.93)
Epoch: [7][100/313]	Time  0.423 ( 0.427)	Data  0.025 ( 0.024)	Loss 2.0820e+00 (2.0806e+00)	Acc@1  87.50 ( 89.10)
Epoch: [7][125/313]	Time  0.419 ( 0.426)	Data  0.016 ( 0.023)	Loss 2.0742e+00 (2.0808e+00)	Acc@1  88.28 ( 88.93)
Epoch: [7][150/313]	Time  0.416 ( 0.425)	Data  0.016 ( 0.022)	Loss 2.0762e+00 (2.0811e+00)	Acc@1  88.28 ( 88.78)
Epoch: [7][175/313]	Time  0.421 ( 0.424)	Data  0.016 ( 0.021)	Loss 2.0801e+00 (2.0810e+00)	Acc@1  88.28 ( 88.75)
Epoch: [7][200/313]	Time  0.418 ( 0.424)	Data  0.017 ( 0.021)	Loss 2.0762e+00 (2.0809e+00)	Acc@1  87.50 ( 88.83)
Epoch: [7][225/313]	Time  0.432 ( 0.423)	Data  0.017 ( 0.020)	Loss 2.0801e+00 (2.0807e+00)	Acc@1  86.72 ( 88.90)
Epoch: [7][250/313]	Time  0.418 ( 0.423)	Data  0.017 ( 0.020)	Loss 2.0762e+00 (2.0806e+00)	Acc@1  89.84 ( 88.88)
Epoch: [7][275/313]	Time  0.417 ( 0.423)	Data  0.017 ( 0.020)	Loss 2.0684e+00 (2.0804e+00)	Acc@1  88.28 ( 88.93)
Epoch: [7][300/313]	Time  0.418 ( 0.423)	Data  0.018 ( 0.019)	Loss 2.0938e+00 (2.0803e+00)	Acc@1  87.50 ( 88.98)
Validate: [ 0/79]	Time  0.962 ( 0.962)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.221 ( 0.255)	Loss 2.0801e+00 (2.0805e+00)	Prompt Acc@1  90.62 ( 88.73)
Validate: [50/79]	Time  0.220 ( 0.239)	Loss 2.0781e+00 (2.0800e+00)	Prompt Acc@1  87.50 ( 88.91)
Validate: [75/79]	Time  0.221 ( 0.235)	Loss 2.0820e+00 (2.0805e+00)	Prompt Acc@1  88.28 ( 88.96)
 * Prompt Acc@1 89.010
There's no improvement for 2 epochs.
Training mode
Epoch: [8][  0/313]	Time  1.219 ( 1.219)	Data  0.796 ( 0.796)	Loss 2.0840e+00 (2.0840e+00)	Acc@1  90.62 ( 90.62)
Epoch: [8][ 25/313]	Time  0.417 ( 0.452)	Data  0.017 ( 0.048)	Loss 2.0820e+00 (2.0799e+00)	Acc@1  89.06 ( 89.09)
Epoch: [8][ 50/313]	Time  0.426 ( 0.437)	Data  0.017 ( 0.033)	Loss 2.0801e+00 (2.0803e+00)	Acc@1  90.62 ( 89.05)
Epoch: [8][ 75/313]	Time  0.417 ( 0.432)	Data  0.017 ( 0.028)	Loss 2.0762e+00 (2.0807e+00)	Acc@1  92.19 ( 88.91)
Epoch: [8][100/313]	Time  0.423 ( 0.429)	Data  0.016 ( 0.025)	Loss 2.0820e+00 (2.0802e+00)	Acc@1  86.72 ( 89.06)
Epoch: [8][125/313]	Time  0.413 ( 0.427)	Data  0.016 ( 0.024)	Loss 2.0742e+00 (2.0804e+00)	Acc@1  88.28 ( 88.89)
Epoch: [8][150/313]	Time  0.437 ( 0.426)	Data  0.017 ( 0.023)	Loss 2.0762e+00 (2.0808e+00)	Acc@1  88.28 ( 88.74)
Epoch: [8][175/313]	Time  0.421 ( 0.426)	Data  0.017 ( 0.022)	Loss 2.0801e+00 (2.0806e+00)	Acc@1  88.28 ( 88.72)
Epoch: [8][200/313]	Time  0.421 ( 0.425)	Data  0.017 ( 0.021)	Loss 2.0762e+00 (2.0805e+00)	Acc@1  87.50 ( 88.81)
Epoch: [8][225/313]	Time  0.415 ( 0.425)	Data  0.018 ( 0.021)	Loss 2.0801e+00 (2.0804e+00)	Acc@1  86.72 ( 88.89)
Epoch: [8][250/313]	Time  0.418 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0742e+00 (2.0803e+00)	Acc@1  90.62 ( 88.87)
Epoch: [8][275/313]	Time  0.418 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0684e+00 (2.0801e+00)	Acc@1  88.28 ( 88.92)
Epoch: [8][300/313]	Time  0.424 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0938e+00 (2.0799e+00)	Acc@1  87.50 ( 88.97)
Validate: [ 0/79]	Time  0.970 ( 0.970)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.222 ( 0.255)	Loss 2.0801e+00 (2.0803e+00)	Prompt Acc@1  90.62 ( 88.73)
Validate: [50/79]	Time  0.222 ( 0.238)	Loss 2.0781e+00 (2.0799e+00)	Prompt Acc@1  87.50 ( 88.94)
Validate: [75/79]	Time  0.221 ( 0.233)	Loss 2.0820e+00 (2.0803e+00)	Prompt Acc@1  89.06 ( 88.98)
 * Prompt Acc@1 89.030
There's no improvement for 3 epochs.
Training mode
Epoch: [9][  0/313]	Time  1.195 ( 1.195)	Data  0.764 ( 0.764)	Loss 2.0840e+00 (2.0840e+00)	Acc@1  90.62 ( 90.62)
Epoch: [9][ 25/313]	Time  0.424 ( 0.452)	Data  0.017 ( 0.047)	Loss 2.0820e+00 (2.0796e+00)	Acc@1  89.06 ( 89.12)
Epoch: [9][ 50/313]	Time  0.423 ( 0.437)	Data  0.019 ( 0.032)	Loss 2.0801e+00 (2.0801e+00)	Acc@1  90.62 ( 89.08)
Epoch: [9][ 75/313]	Time  0.416 ( 0.432)	Data  0.017 ( 0.028)	Loss 2.0762e+00 (2.0805e+00)	Acc@1  92.19 ( 88.92)
Epoch: [9][100/313]	Time  0.425 ( 0.429)	Data  0.018 ( 0.025)	Loss 2.0820e+00 (2.0800e+00)	Acc@1  86.72 ( 89.07)
Epoch: [9][125/313]	Time  0.421 ( 0.428)	Data  0.018 ( 0.024)	Loss 2.0742e+00 (2.0803e+00)	Acc@1  88.28 ( 88.91)
Epoch: [9][150/313]	Time  0.419 ( 0.427)	Data  0.018 ( 0.023)	Loss 2.0762e+00 (2.0806e+00)	Acc@1  88.28 ( 88.74)
Epoch: [9][175/313]	Time  0.440 ( 0.426)	Data  0.016 ( 0.022)	Loss 2.0781e+00 (2.0805e+00)	Acc@1  88.28 ( 88.72)
Epoch: [9][200/313]	Time  0.414 ( 0.426)	Data  0.016 ( 0.021)	Loss 2.0762e+00 (2.0804e+00)	Acc@1  88.28 ( 88.80)
Epoch: [9][225/313]	Time  0.422 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0801e+00 (2.0802e+00)	Acc@1  86.72 ( 88.87)
Epoch: [9][250/313]	Time  0.413 ( 0.425)	Data  0.016 ( 0.020)	Loss 2.0742e+00 (2.0801e+00)	Acc@1  89.84 ( 88.85)
Epoch: [9][275/313]	Time  0.422 ( 0.424)	Data  0.015 ( 0.020)	Loss 2.0684e+00 (2.0800e+00)	Acc@1  88.28 ( 88.91)
Epoch: [9][300/313]	Time  0.425 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0938e+00 (2.0798e+00)	Acc@1  87.50 ( 88.95)
Validate: [ 0/79]	Time  0.947 ( 0.947)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.220 ( 0.251)	Loss 2.0801e+00 (2.0803e+00)	Prompt Acc@1  90.62 ( 88.76)
Validate: [50/79]	Time  0.217 ( 0.236)	Loss 2.0781e+00 (2.0797e+00)	Prompt Acc@1  87.50 ( 88.88)
Validate: [75/79]	Time  0.220 ( 0.232)	Loss 2.0820e+00 (2.0802e+00)	Prompt Acc@1  89.06 ( 88.91)
 * Prompt Acc@1 88.950
There's no improvement for 4 epochs.
Training mode
Epoch: [10][  0/313]	Time  1.149 ( 1.149)	Data  0.730 ( 0.730)	Loss 2.0840e+00 (2.0840e+00)	Acc@1  90.62 ( 90.62)
Epoch: [10][ 25/313]	Time  0.413 ( 0.448)	Data  0.017 ( 0.044)	Loss 2.0820e+00 (2.0796e+00)	Acc@1  89.06 ( 89.00)
Epoch: [10][ 50/313]	Time  0.423 ( 0.434)	Data  0.017 ( 0.031)	Loss 2.0801e+00 (2.0801e+00)	Acc@1  89.84 ( 88.96)
Epoch: [10][ 75/313]	Time  0.416 ( 0.430)	Data  0.017 ( 0.026)	Loss 2.0762e+00 (2.0805e+00)	Acc@1  92.19 ( 88.85)
Epoch: [10][100/313]	Time  0.423 ( 0.427)	Data  0.017 ( 0.024)	Loss 2.0820e+00 (2.0800e+00)	Acc@1  86.72 ( 88.99)
Epoch: [10][125/313]	Time  0.422 ( 0.426)	Data  0.016 ( 0.023)	Loss 2.0742e+00 (2.0802e+00)	Acc@1  88.28 ( 88.83)
Epoch: [10][150/313]	Time  0.416 ( 0.425)	Data  0.017 ( 0.022)	Loss 2.0762e+00 (2.0805e+00)	Acc@1  88.28 ( 88.67)
Epoch: [10][175/313]	Time  0.419 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0781e+00 (2.0804e+00)	Acc@1  88.28 ( 88.65)
Epoch: [10][200/313]	Time  0.429 ( 0.424)	Data  0.019 ( 0.020)	Loss 2.0762e+00 (2.0803e+00)	Acc@1  89.06 ( 88.74)
Epoch: [10][225/313]	Time  0.419 ( 0.424)	Data  0.018 ( 0.020)	Loss 2.0801e+00 (2.0802e+00)	Acc@1  86.72 ( 88.82)
Epoch: [10][250/313]	Time  0.420 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0742e+00 (2.0800e+00)	Acc@1  89.84 ( 88.81)
Epoch: [10][275/313]	Time  0.421 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0684e+00 (2.0799e+00)	Acc@1  88.28 ( 88.88)
Epoch: [10][300/313]	Time  0.422 ( 0.423)	Data  0.016 ( 0.019)	Loss 2.0938e+00 (2.0797e+00)	Acc@1  87.50 ( 88.94)
Validate: [ 0/79]	Time  0.975 ( 0.975)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.81 ( 82.81)
Validate: [25/79]	Time  0.220 ( 0.254)	Loss 2.0801e+00 (2.0802e+00)	Prompt Acc@1  90.62 ( 88.73)
Validate: [50/79]	Time  0.221 ( 0.238)	Loss 2.0781e+00 (2.0797e+00)	Prompt Acc@1  87.50 ( 88.85)
Validate: [75/79]	Time  0.219 ( 0.233)	Loss 2.0820e+00 (2.0801e+00)	Prompt Acc@1  89.06 ( 88.89)
 * Prompt Acc@1 88.930
There's no improvement for 5 epochs.
Training mode
Epoch: [11][  0/313]	Time  1.113 ( 1.113)	Data  0.708 ( 0.708)	Loss 2.0840e+00 (2.0840e+00)	Acc@1  90.62 ( 90.62)
Epoch: [11][ 25/313]	Time  0.428 ( 0.448)	Data  0.018 ( 0.044)	Loss 2.0820e+00 (2.0795e+00)	Acc@1  89.06 ( 88.94)
Epoch: [11][ 50/313]	Time  0.431 ( 0.434)	Data  0.017 ( 0.031)	Loss 2.0801e+00 (2.0800e+00)	Acc@1  89.84 ( 88.88)
Epoch: [11][ 75/313]	Time  0.414 ( 0.430)	Data  0.016 ( 0.026)	Loss 2.0762e+00 (2.0804e+00)	Acc@1  91.41 ( 88.76)
Epoch: [11][100/313]	Time  0.428 ( 0.428)	Data  0.016 ( 0.024)	Loss 2.0820e+00 (2.0799e+00)	Acc@1  86.72 ( 88.92)
Epoch: [11][125/313]	Time  0.426 ( 0.427)	Data  0.017 ( 0.023)	Loss 2.0742e+00 (2.0801e+00)	Acc@1  88.28 ( 88.78)
Epoch: [11][150/313]	Time  0.413 ( 0.426)	Data  0.016 ( 0.022)	Loss 2.0762e+00 (2.0805e+00)	Acc@1  88.28 ( 88.63)
Epoch: [11][175/313]	Time  0.422 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0781e+00 (2.0803e+00)	Acc@1  88.28 ( 88.62)
Epoch: [11][200/313]	Time  0.427 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0762e+00 (2.0803e+00)	Acc@1  88.28 ( 88.70)
Epoch: [11][225/313]	Time  0.426 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0801e+00 (2.0801e+00)	Acc@1  86.72 ( 88.78)
Epoch: [11][250/313]	Time  0.414 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0742e+00 (2.0800e+00)	Acc@1  89.84 ( 88.77)
Epoch: [11][275/313]	Time  0.420 ( 0.424)	Data  0.017 ( 0.020)	Loss 2.0684e+00 (2.0798e+00)	Acc@1  88.28 ( 88.84)
Epoch: [11][300/313]	Time  0.416 ( 0.423)	Data  0.017 ( 0.019)	Loss 2.0938e+00 (2.0796e+00)	Acc@1  86.72 ( 88.90)
Validate: [ 0/79]	Time  0.945 ( 0.945)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.03 ( 82.03)
Validate: [25/79]	Time  0.221 ( 0.266)	Loss 2.0801e+00 (2.0802e+00)	Prompt Acc@1  90.62 ( 88.76)
Validate: [50/79]	Time  0.232 ( 0.247)	Loss 2.0781e+00 (2.0796e+00)	Prompt Acc@1  87.50 ( 88.88)
Validate: [75/79]	Time  0.218 ( 0.241)	Loss 2.0820e+00 (2.0800e+00)	Prompt Acc@1  89.06 ( 88.91)
 * Prompt Acc@1 88.950
There's no improvement for 6 epochs.
Training mode
Epoch: [12][  0/313]	Time  1.177 ( 1.177)	Data  0.755 ( 0.755)	Loss 2.0840e+00 (2.0840e+00)	Acc@1  90.62 ( 90.62)
Epoch: [12][ 25/313]	Time  0.419 ( 0.452)	Data  0.017 ( 0.047)	Loss 2.0820e+00 (2.0793e+00)	Acc@1  89.06 ( 89.00)
Epoch: [12][ 50/313]	Time  0.423 ( 0.437)	Data  0.023 ( 0.033)	Loss 2.0801e+00 (2.0799e+00)	Acc@1  89.84 ( 88.91)
Epoch: [12][ 75/313]	Time  0.414 ( 0.431)	Data  0.016 ( 0.027)	Loss 2.0762e+00 (2.0803e+00)	Acc@1  91.41 ( 88.75)
Epoch: [12][100/313]	Time  0.418 ( 0.428)	Data  0.015 ( 0.025)	Loss 2.0820e+00 (2.0798e+00)	Acc@1  86.72 ( 88.94)
Epoch: [12][125/313]	Time  0.429 ( 0.426)	Data  0.016 ( 0.023)	Loss 2.0742e+00 (2.0800e+00)	Acc@1  88.28 ( 88.77)
Epoch: [12][150/313]	Time  0.415 ( 0.425)	Data  0.017 ( 0.022)	Loss 2.0762e+00 (2.0804e+00)	Acc@1  88.28 ( 88.62)
Epoch: [12][175/313]	Time  0.425 ( 0.425)	Data  0.016 ( 0.021)	Loss 2.0781e+00 (2.0803e+00)	Acc@1  88.28 ( 88.61)
Epoch: [12][200/313]	Time  0.428 ( 0.424)	Data  0.017 ( 0.021)	Loss 2.0762e+00 (2.0802e+00)	Acc@1  89.06 ( 88.70)
Epoch: [12][225/313]	Time  0.413 ( 0.424)	Data  0.016 ( 0.020)	Loss 2.0801e+00 (2.0800e+00)	Acc@1  86.72 ( 88.79)
Epoch: [12][250/313]	Time  0.419 ( 0.423)	Data  0.016 ( 0.020)	Loss 2.0742e+00 (2.0799e+00)	Acc@1  89.84 ( 88.78)
Epoch: [12][275/313]	Time  0.414 ( 0.423)	Data  0.016 ( 0.020)	Loss 2.0684e+00 (2.0797e+00)	Acc@1  89.06 ( 88.86)
Epoch: [12][300/313]	Time  0.415 ( 0.423)	Data  0.016 ( 0.019)	Loss 2.0938e+00 (2.0795e+00)	Acc@1  86.72 ( 88.91)
Validate: [ 0/79]	Time  0.940 ( 0.940)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.03 ( 82.03)
Validate: [25/79]	Time  0.265 ( 0.252)	Loss 2.0801e+00 (2.0802e+00)	Prompt Acc@1  90.62 ( 88.79)
Validate: [50/79]	Time  0.221 ( 0.237)	Loss 2.0781e+00 (2.0795e+00)	Prompt Acc@1  87.50 ( 88.85)
Validate: [75/79]	Time  0.224 ( 0.232)	Loss 2.0820e+00 (2.0799e+00)	Prompt Acc@1  89.06 ( 88.89)
 * Prompt Acc@1 88.930
There's no improvement for 7 epochs.
The training halted by early stopping criterion.
Validate: [ 0/79]	Time  0.999 ( 0.999)	Loss 2.0996e+00 (2.0996e+00)	Prompt Acc@1  82.03 ( 82.03)
Validate: [25/79]	Time  0.217 ( 0.253)	Loss 2.0801e+00 (2.0802e+00)	Prompt Acc@1  90.62 ( 88.79)
Validate: [50/79]	Time  0.224 ( 0.237)	Loss 2.0781e+00 (2.0795e+00)	Prompt Acc@1  87.50 ( 88.85)
Validate: [75/79]	Time  0.218 ( 0.232)	Loss 2.0820e+00 (2.0799e+00)	Prompt Acc@1  89.06 ( 88.89)
 * Prompt Acc@1 88.930
Validate: [ 0/79]	Time  0.950 ( 0.950)	Loss 2.0820e+00 (2.0820e+00)	Prompt Acc@1  90.62 ( 90.62)
Validate: [25/79]	Time  0.221 ( 0.251)	Loss 2.0723e+00 (2.0773e+00)	Prompt Acc@1  91.41 ( 90.08)
Validate: [50/79]	Time  0.224 ( 0.237)	Loss 2.0820e+00 (2.0786e+00)	Prompt Acc@1  88.28 ( 89.25)
Validate: [75/79]	Time  0.220 ( 0.232)	Loss 2.0781e+00 (2.0795e+00)	Prompt Acc@1  89.84 ( 89.23)
 * Prompt Acc@1 89.170
Running experiment on cifar10 with random_patch and prompt size 1
Namespace(print_freq=25, save_freq=50, batch_size=128, num_workers=3, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=7, model='clip', arch='ViT-B/32', method='random_patch', prompt_size=1, text_prompt_template='This is a photo of a {}', visualize_prompt=False, root='/scratch/lcur0649', dataset='cifar10', image_size=224, test_noise=False, seed=0, model_dir='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/checkpoints', image_dir='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/images', filename='random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume=None, evaluate=False, gpu=None, use_wandb=False, device='cuda', model_folder='/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/checkpoints/random_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Files already downloaded and verified
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
Turning off gradients in both the image and the text encoder
Parameters to be updated:
"Parameters to be updated: {'prompt_learner.random_patch'}"
Number of prompt parameters:  3
Training mode
Epoch: [0][  0/313]	Time  2.256 ( 2.256)	Data  0.752 ( 0.752)	Loss 2.0938e+00 (2.0938e+00)	Acc@1  85.16 ( 85.16)
Epoch: [0][ 25/313]	Time  0.423 ( 0.489)	Data  0.017 ( 0.045)	Loss 2.0957e+00 (2.0862e+00)	Acc@1  80.47 ( 88.22)
Epoch: [0][ 50/313]	Time  0.435 ( 0.454)	Data  0.016 ( 0.031)	Loss 2.0879e+00 (2.0862e+00)	Acc@1  89.06 ( 88.57)
Epoch: [0][ 75/313]	Time  0.419 ( 0.443)	Data  0.016 ( 0.026)	Loss 2.0977e+00 (2.0870e+00)	Acc@1  86.72 ( 88.35)
Epoch: [0][100/313]	Time  0.414 ( 0.437)	Data  0.016 ( 0.024)	Loss 2.0801e+00 (2.0871e+00)	Acc@1  92.19 ( 88.43)
Epoch: [0][125/313]	Time  0.419 ( 0.434)	Data  0.020 ( 0.023)	Loss 2.0840e+00 (2.0871e+00)	Acc@1  86.72 ( 88.47)
Epoch: [0][150/313]	Time  0.420 ( 0.432)	Data  0.016 ( 0.022)	Loss 2.0840e+00 (2.0861e+00)	Acc@1  91.41 ( 88.65)
Epoch: [0][175/313]	Time  0.425 ( 0.430)	Data  0.016 ( 0.021)	Loss 2.0762e+00 (2.0856e+00)	Acc@1  92.19 ( 88.58)
Epoch: [0][200/313]	Time  0.418 ( 0.429)	Data  0.017 ( 0.021)	Loss 2.0840e+00 (2.0854e+00)	Acc@1  89.06 ( 88.58)
Epoch: [0][225/313]	Time  0.415 ( 0.428)	Data  0.017 ( 0.020)	Loss 2.0742e+00 (2.0847e+00)	Acc@1  88.28 ( 88.70)
Epoch: [0][250/313]	Time  0.418 ( 0.427)	Data  0.016 ( 0.020)	Loss 2.0820e+00 (2.0841e+00)	Acc@1  89.84 ( 88.83)
Epoch: [0][275/313]	Time  0.427 ( 0.427)	Data  0.016 ( 0.020)	Loss 2.0918e+00 (2.0836e+00)	Acc@1  87.50 ( 88.94)
Epoch: [0][300/313]	Time  0.415 ( 0.427)	Data  0.016 ( 0.019)	Loss 2.0820e+00 (2.0834e+00)	Acc@1  90.62 ( 88.97)
Validate: [ 0/79]	Time  0.940 ( 0.940)	Loss 2.0762e+00 (2.0762e+00)	Prompt Acc@1  92.19 ( 92.19)
Validate: [25/79]	Time  0.222 ( 0.254)	Loss 2.0723e+00 (2.0832e+00)	Prompt Acc@1  86.72 ( 88.40)
Validate: [50/79]	Time  0.219 ( 0.238)	Loss 2.0820e+00 (2.0817e+00)	Prompt Acc@1  83.59 ( 88.80)
Validate: [75/79]	Time  0.221 ( 0.233)	Loss 2.0645e+00 (2.0809e+00)	Prompt Acc@1  92.97 ( 88.89)
 * Prompt Acc@1 88.840
saved best file
Training mode
Epoch: [1][  0/313]	Time  1.089 ( 1.089)	Data  0.652 ( 0.652)	Loss 2.0898e+00 (2.0898e+00)	Acc@1  84.38 ( 84.38)
Epoch: [1][ 25/313]	Time  0.423 ( 0.449)	Data  0.016 ( 0.042)	Loss 2.0879e+00 (2.0802e+00)	Acc@1  83.59 ( 88.46)
Epoch: [1][ 50/313]	Time  0.422 ( 0.436)	Data  0.017 ( 0.030)	Loss 2.0781e+00 (2.0795e+00)	Acc@1  90.62 ( 88.82)
Epoch: [1][ 75/313]	Time  0.419 ( 0.432)	Data  0.016 ( 0.026)	Loss 2.0879e+00 (2.0801e+00)	Acc@1  87.50 ( 88.73)
Epoch: [1][100/313]	Time  0.431 ( 0.430)	Data  0.019 ( 0.024)	Loss 2.0742e+00 (2.0799e+00)	Acc@1  88.28 ( 88.85)
Epoch: [1][125/313]	Time  0.416 ( 0.428)	Data  0.016 ( 0.023)	Loss 2.0762e+00 (2.0800e+00)	Acc@1  88.28 ( 88.86)
Epoch: [1][150/313]	Time  0.437 ( 0.427)	Data  0.018 ( 0.022)	Loss 2.0840e+00 (2.0799e+00)	Acc@1  90.62 ( 88.87)
Epoch: [1][175/313]	Time  0.421 ( 0.427)	Data  0.017 ( 0.021)	Loss 2.0781e+00 (2.0803e+00)	Acc@1  90.62 ( 88.64)
Epoch: [1][200/313]	Time  0.417 ( 0.426)	Data  0.016 ( 0.021)	Loss 2.0781e+00 (2.0805e+00)	Acc@1  89.84 ( 88.60)
Epoch: [1][225/313]	Time  0.430 ( 0.426)	Data  0.016 ( 0.020)	Loss 2.0820e+00 (2.0802e+00)	Acc@1  88.28 ( 88.69)
Epoch: [1][250/313]	Time  0.422 ( 0.425)	Data  0.017 ( 0.020)	Loss 2.0840e+00 (2.0800e+00)	Acc@1  91.41 ( 88.77)
Epoch: [1][275/313]	Time  0.424 ( 0.425)	Data  0.016 ( 0.020)	Loss 2.0957e+00 (2.0799e+00)	Acc@1  85.94 ( 88.89)
Epoch: [1][300/313]	Time  0.420 ( 0.425)	Data  0.016 ( 0.020)	Loss 2.0781e+00 (2.0800e+00)	Acc@1  92.19 ( 88.90)
Validate: [ 0/79]	Time  0.968 ( 0.968)	Loss 2.0762e+00 (2.0762e+00)	Prompt Acc@1  90.62 ( 90.62)
Validate: [25/79]	Time  0.228 ( 0.262)	Loss 2.0801e+00 (2.0835e+00)	Prompt Acc@1  85.16 ( 87.98)
Validate: [50/79]	Time  0.224 ( 0.244)	Loss 2.0820e+00 (2.0817e+00)	Prompt Acc@1  85.16 ( 88.54)
Validate: [75/79]	Time  0.221 ( 0.238)	Loss 2.0645e+00 (2.0808e+00)	Prompt Acc@1  93.75 ( 88.65)
 * Prompt Acc@1 88.650
There's no improvement for 1 epochs.
Training mode
slurmstepd: error: *** JOB 10435968 ON r31n6 CANCELLED AT 2022-12-02T14:22:08 ***
