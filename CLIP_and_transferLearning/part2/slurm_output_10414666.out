Running experiment on cifar10 with fixed_patch and prompt size 1
Namespace(print_freq=10, save_freq=50, batch_size=128, num_workers=12, epochs=20, square_size=8, optim='sgd', learning_rate=40, weight_decay=0, warmup=1000, momentum=0.9, patience=1000, model='clip', arch='ViT-B/32', method='fixed_patch', prompt_size=1, text_prompt_template='This is a photo of a {}', visualize_prompt=False, root='/scratch/lcur0649', dataset='cifar10', image_size=224, test_noise=False, seed=0, model_dir='./save/models', image_dir='./save/images', filename='fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1', trial=1, resume=None, evaluate=False, gpu=None, use_wandb=False, device='cuda', model_folder='./save/models/fixed_patch_1_cifar10_clip_ViT-B/32_sgd_lr_40_decay_0_bsz_128_warmup_1000_trial_1')
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /scratch/lcur0649/cifar-10-python.tar.gz
  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 65536/170498071 [00:00<08:30, 333618.84it/s]  0%|          | 131072/170498071 [00:00<07:07, 398537.68it/s]  0%|          | 196608/170498071 [00:00<05:53, 482377.84it/s]  0%|          | 262144/170498071 [00:00<05:53, 481979.61it/s]  0%|          | 425984/170498071 [00:00<03:27, 818330.40it/s]  0%|          | 786432/170498071 [00:00<01:46, 1590615.37it/s]  1%|          | 1572864/170498071 [00:00<00:49, 3396936.93it/s]  2%|▏         | 2981888/170498071 [00:00<00:25, 6504218.77it/s]  3%|▎         | 4653056/170498071 [00:01<00:17, 9473394.90it/s]  4%|▎         | 6258688/170498071 [00:01<00:14, 11399628.64it/s]  5%|▍         | 8093696/170498071 [00:01<00:12, 13368123.76it/s]  6%|▌         | 9895936/170498071 [00:01<00:10, 14689929.12it/s]  7%|▋         | 11862016/170498071 [00:01<00:09, 16136877.52it/s]  8%|▊         | 13795328/170498071 [00:01<00:09, 17028866.67it/s]  9%|▉         | 15925248/170498071 [00:01<00:08, 18285059.53it/s] 11%|█         | 18120704/170498071 [00:01<00:08, 18416130.75it/s] 12%|█▏        | 20447232/170498071 [00:01<00:07, 19763722.12it/s] 13%|█▎        | 22872064/170498071 [00:02<00:07, 20986427.41it/s] 15%|█▍        | 25526272/170498071 [00:02<00:06, 22543165.49it/s] 17%|█▋        | 28344320/170498071 [00:02<00:05, 24073981.55it/s] 18%|█▊        | 31326208/170498071 [00:02<00:05, 25746118.59it/s] 20%|██        | 34439168/170498071 [00:02<00:04, 27309330.65it/s] 22%|██▏       | 37257216/170498071 [00:02<00:04, 27467820.03it/s] 24%|██▎       | 40173568/170498071 [00:02<00:04, 27847481.20it/s] 25%|██▌       | 43417600/170498071 [00:02<00:04, 29183706.09it/s] 27%|██▋       | 46497792/170498071 [00:02<00:04, 29658803.37it/s] 29%|██▉       | 49643520/170498071 [00:02<00:04, 30111605.59it/s] 31%|███       | 52756480/170498071 [00:03<00:03, 30415072.05it/s] 33%|███▎      | 55902208/170498071 [00:03<00:03, 30683274.63it/s] 35%|███▍      | 59080704/170498071 [00:03<00:03, 31008778.51it/s] 37%|███▋      | 62259200/170498071 [00:03<00:03, 31227660.44it/s] 38%|███▊      | 65470464/170498071 [00:03<00:03, 31477387.70it/s] 40%|████      | 68648960/170498071 [00:03<00:03, 31387365.55it/s] 42%|████▏     | 71794688/170498071 [00:03<00:03, 31264751.41it/s] 44%|████▍     | 74940416/170498071 [00:03<00:03, 30741823.04it/s] 46%|████▌     | 78020608/170498071 [00:03<00:03, 29463748.54it/s] 48%|████▊     | 81002496/170498071 [00:03<00:03, 29551909.02it/s] 49%|████▉     | 84082688/170498071 [00:04<00:02, 29832306.96it/s] 51%|█████     | 87326720/170498071 [00:04<00:02, 30582000.89it/s] 53%|█████▎    | 90472448/170498071 [00:04<00:02, 30751610.37it/s] 55%|█████▍    | 93618176/170498071 [00:04<00:02, 30768753.93it/s] 57%|█████▋    | 96763904/170498071 [00:04<00:02, 30228900.53it/s] 59%|█████▊    | 100040704/170498071 [00:04<00:02, 30955126.53it/s] 61%|██████    | 103284736/170498071 [00:04<00:02, 31383282.32it/s] 62%|██████▏   | 106430464/170498071 [00:04<00:02, 31137024.46it/s] 64%|██████▍   | 109674496/170498071 [00:04<00:01, 31513121.47it/s] 66%|██████▌   | 112852992/170498071 [00:04<00:01, 31236769.55it/s] 68%|██████▊   | 116064256/170498071 [00:05<00:01, 31276648.28it/s] 70%|██████▉   | 119209984/170498071 [00:05<00:01, 31145592.58it/s] 72%|███████▏  | 122421248/170498071 [00:05<00:01, 31268376.46it/s] 74%|███████▎  | 125599744/170498071 [00:05<00:01, 30892864.11it/s] 76%|███████▌  | 128745472/170498071 [00:05<00:01, 30885415.47it/s] 77%|███████▋  | 132022272/170498071 [00:05<00:01, 31416109.66it/s] 79%|███████▉  | 135168000/170498071 [00:05<00:01, 31358990.87it/s] 81%|████████  | 138412032/170498071 [00:05<00:01, 31670530.27it/s] 83%|████████▎ | 141623296/170498071 [00:05<00:00, 31796396.30it/s] 85%|████████▍ | 144834560/170498071 [00:05<00:00, 31885934.76it/s] 87%|████████▋ | 148045824/170498071 [00:06<00:00, 31699785.65it/s] 89%|████████▊ | 151224320/170498071 [00:06<00:00, 31502378.08it/s] 91%|█████████ | 154402816/170498071 [00:06<00:00, 31086027.39it/s] 92%|█████████▏| 157646848/170498071 [00:06<00:00, 30687606.24it/s] 94%|█████████▍| 160792576/170498071 [00:06<00:00, 30545539.80it/s] 96%|█████████▌| 163971072/170498071 [00:06<00:00, 30711459.89it/s] 98%|█████████▊| 167182336/170498071 [00:06<00:00, 30545064.08it/s]100%|█████████▉| 170393600/170498071 [00:06<00:00, 30999676.53it/s]100%|██████████| 170498071/170498071 [00:06<00:00, 24988275.53it/s]
/home/lcur0649/.conda/envs/dl2022/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Extracting /scratch/lcur0649/cifar-10-python.tar.gz to /scratch/lcur0649
Files already downloaded and verified
Building custom CLIP
Loading CLIP (backbone: ViT-B/32)
  0%|                                               | 0.00/338M [00:00<?, ?iB/s]  1%|▍                                     | 3.48M/338M [00:00<00:09, 36.5MiB/s]  6%|██▍                                    | 21.2M/338M [00:00<00:02, 124MiB/s] 12%|████▊                                  | 42.1M/338M [00:00<00:01, 168MiB/s] 19%|███████▌                               | 64.9M/338M [00:00<00:01, 196MiB/s] 26%|██████████▎                            | 89.1M/338M [00:00<00:01, 217MiB/s] 34%|█████████████▌                          | 115M/338M [00:00<00:00, 234MiB/s] 42%|████████████████▉                       | 143M/338M [00:00<00:00, 255MiB/s] 50%|███████████████████▊                    | 167M/338M [00:00<00:00, 250MiB/s] 57%|██████████████████████▋                 | 191M/338M [00:00<00:00, 208MiB/s] 63%|█████████████████████████               | 212M/338M [00:01<00:00, 189MiB/s] 68%|███████████████████████████▍            | 231M/338M [00:01<00:00, 180MiB/s] 74%|█████████████████████████████▍          | 249M/338M [00:01<00:00, 171MiB/s] 79%|███████████████████████████████▍        | 266M/338M [00:01<00:00, 167MiB/s] 83%|█████████████████████████████████▍      | 282M/338M [00:01<00:00, 164MiB/s] 88%|███████████████████████████████████▏    | 297M/338M [00:01<00:00, 161MiB/s] 93%|█████████████████████████████████████   | 313M/338M [00:01<00:00, 159MiB/s] 97%|██████████████████████████████████████▉ | 328M/338M [00:01<00:00, 158MiB/s]100%|████████████████████████████████████████| 338M/338M [00:01<00:00, 179MiB/s]
List of prompts:
['This is a photo of a airplane',
 'This is a photo of a automobile',
 'This is a photo of a bird',
 'This is a photo of a cat',
 'This is a photo of a deer',
 'This is a photo of a dog',
 'This is a photo of a frog',
 'This is a photo of a horse',
 'This is a photo of a ship',
 'This is a photo of a truck']
Traceback (most recent call last):
  File "/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/.//main.py", line 150, in <module>
    main()
  File "/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/.//main.py", line 139, in main
    learn = Learner(args)
  File "/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/learner.py", line 56, in __init__
    self.vpt = CustomCLIP(args, self.test_dataset, template=PROMPT_TEMPLATE)
  File "/home/lcur0649/uvadlc_practicals_2022/assignment2/part2/vpt_model.py", line 88, in __init__
    text_features = clip_model.encode_text(text)
NameError: name 'text' is not defined. Did you mean: 'next'?
